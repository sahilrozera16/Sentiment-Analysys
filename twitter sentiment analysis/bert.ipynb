{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy_of_NLP_with_Bert_for_Sentiment_Analysis (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ynPRbJviL-39"
      },
      "source": [
        "# NLP with Bert for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z82c-Fcay0a3"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "128NswTg1MLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa3f9208-be38-4e38-83bf-ce3c37bc847f"
      },
      "source": [
        "!pip3 install ktrain"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ktrain\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/94/dbee68fd93255f7604092f9cd3c60d3aa550808099443a28a36d79cd7632/ktrain-0.18.4.tar.gz (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 128kB/s \n",
            "\u001b[?25hCollecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.4.1)\n",
            "Collecting scikit-learn==0.21.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.2.3)\n",
            "Collecting keras_bert>=0.81.0\n",
            "  Downloading https://files.pythonhosted.org/packages/06/fc/45434550f446e6e1c9cac715e5a2f34a6fa599abd98563f728c2d6df4332/keras-bert-0.85.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.16.0)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet==2.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/4e/847feebfc3e71c773b23ee06c74687b8c50a5a6d6aaff452a0a4f4eb9a32/cchardet-2.1.5-cp36-cp36m-manylinux1_x86_64.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.4)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.4.0)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.4)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.0)\n",
            "Collecting transformers>=2.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n",
            "Collecting syntok\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n",
            "Collecting whoosh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.18.5)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.12.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 32.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.30.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 32.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Collecting Keras>=2.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n",
            "Collecting keras-transformer>=0.38.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.6.20)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.5.3)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (7.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (2.11.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.13)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.3.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (19.3.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.22.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (4.41.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (2.3)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 32.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (49.1.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.1)\n",
            "Collecting keras-pos-embd>=0.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.27.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->ktrain) (1.52.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.11.0->ktrain) (7.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.3.0)\n",
            "Collecting keras-self-attention==0.46.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n",
            "Building wheels for collected packages: ktrain, keras-bert, langdetect, seqeval, syntok, gast, keras-transformer, sacremoses, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.18.4-cp36-none-any.whl size=25253172 sha256=8a573842bfb1862c8d5e533d6176540cfc61d4969eb8f790a8006e8c8c251280\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ca/65/2bff349d7d2f2e0710d993ddb5d9a2ff2431c617ed3a7a68d7\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.85.0-cp36-none-any.whl size=34303 sha256=936e4e62fea87f7f3325c4c9533e150c4facc489a1c12946adcf6fcfbb8a0ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/7a/13/40e59e2587ebfdba717d5ecc4c89c614f06c8137e515fa8b26\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=88d16a3a84aa2630d02245722a37b7859fdb5d268fba18f0ab8906451055e134\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=68b30422101d88692588544b756e735b6382467fc3a9d67bdb92fe0c6515049d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.3.1-cp36-none-any.whl size=20918 sha256=5c93d2f6383166982816acbdf51687917baec802335e123a9b995d75a60f21b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=ddc3eed2617d69e2f8ae963acb4e946ba0e3c31bc849e3537f76a844fec9b74c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=b313365b316f9610d947ce1595939c3cc990a5de493f7d7824537a80fd35331f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b14f86dc95f1b308b3cf091e1726f9ebe3065a61f02e87f5087b4f0a7e5c7af0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=3165cb0ce6130a8e89e4b333f1fc85c5100b84757a414c96bb3ed4bc98bba1ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15611 sha256=0ea6fd0e080c1345892cc0b5ab3b961776f03f8820a754a615b8e1ced81e23ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=9de8e892963f13587c28a79ff75beedefd297e6dcf0a33a0d2be810a667e6e52\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=17d625a4b225d7ad981b3081f197580c88e47b73f46bc27aa4c4f58bb4777011\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4558 sha256=c6325aba9f2eaa9fe8478a19eff95486f0eeb41e7c22563db94f07a6f34d355e\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=e6bd6a5046bf4a8caad9f217ddded16a55d4e6f68e62fcb665ed7a71735f3c4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
            "Successfully built ktrain keras-bert langdetect seqeval syntok gast keras-transformer sacremoses keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow, scikit-learn, Keras, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, cchardet, seqeval, sacremoses, sentencepiece, tokenizers, transformers, syntok, whoosh, ktrain\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed Keras-2.4.3 cchardet-2.1.5 gast-0.2.2 keras-bert-0.85.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.18.4 langdetect-1.0.8 sacremoses-0.0.43 scikit-learn-0.21.3 sentencepiece-0.1.91 seqeval-0.0.12 syntok-1.3.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tokenizers-0.8.1rc1 transformers-3.0.2 whoosh-2.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltFbiP3f2vnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih_NZWz5xRLM",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4IKKw-Rw7Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train_E6oV3lV.csv')\n",
        "test = pd.read_csv('test_tweets_anuFYb8.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhqiMvQhxDMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fe438a6-8495-47c9-bad8-27333c4068d3"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31962, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWbNR_eqxDQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47ecd343-f152-4fc7-ba32-e4d8e45cdbea"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17197, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1vVvnH0xfOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "92f974a5-ebe0-4063-a23c-8a83964d580e"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZs809oAxfPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "24711140-1c55-44fa-b873-b4e8c20ccc7c"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s...\n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "3  31966  is the hp and the cursed child book up for res...\n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo82CPlDybXk",
        "colab_type": "text"
      },
      "source": [
        "### Creating the training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pxt7kYGxfXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1d7c2122-c055-413b-cc92-aa714374b56e"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(train,\n",
        "                                                                   text_column='tweet',\n",
        "                                                                   label_columns=['label'],\n",
        "                                                                   maxlen=500,\n",
        "                                                                   preprocess_mode='bert')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFrsQHdn3D62",
        "colab_type": "text"
      },
      "source": [
        "## Part 2: Building the BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vez8UKHaxfWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ffce2dcf-3cb6-49fb-fd68-0d3274a9799c"
      },
      "source": [
        "model = text.text_classifier(name='bert',\n",
        "                             train_data=(x_train, y_train),\n",
        "                             preproc=preproc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 500\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_l4-APf3N6t",
        "colab_type": "text"
      },
      "source": [
        "## Part 3: Training the BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq72kc5exDPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = ktrain.get_learner(model=model,\n",
        "                             train_data=(x_train, y_train),\n",
        "                             val_data=(x_test, y_test),\n",
        "                             batch_size=6)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRqHqoIQ51oF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4ad01f91-418f-42af-e86a-c030b23974e8"
      },
      "source": [
        "learner.fit_onecycle(lr=2e-5,\n",
        "                     epochs=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Train on 28765 samples, validate on 3197 samples\n",
            "28765/28765 [==============================] - 8350s 290ms/sample - loss: 0.1309 - accuracy: 0.9549 - val_loss: 0.1007 - val_accuracy: 0.9659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba322839e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm1ZFqgwzc5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d1d3d796-ae6d-448d-fff8-46bd869bf454"
      },
      "source": [
        "learner.validate(val_data=(x_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      2964\n",
            "           1       0.87      0.63      0.73       233\n",
            "\n",
            "    accuracy                           0.97      3197\n",
            "   macro avg       0.92      0.81      0.85      3197\n",
            "weighted avg       0.96      0.97      0.96      3197\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2942,   22],\n",
              "       [  87,  146]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGll6eMMDIEk",
        "colab_type": "text"
      },
      "source": [
        "## How to Use Our Trained BERT Model\n",
        "\n",
        "We can call the `learner.get_predictor` method to obtain a Predictor object capable of making predictions on new raw data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xSesGYzDMVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjMEcZdbD0y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe475e71-e44e-4a49-d8c0-d08d9ecca615"
      },
      "source": [
        "predictor.get_classes()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urNnjHWcBQzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "7dab8b61-9b67-4cfe-893a-c337d3ed8b07"
      },
      "source": [
        "test_tweets = test['tweet'].values\n",
        "test_tweets"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['#studiolife #aislife #requires #passion #dedication #willpower   to find #newmaterialsâ\\x80¦ ',\n",
              "       ' @user #white #supremacists want everyone to see the new â\\x80\\x98  #birdsâ\\x80\\x99 #movie â\\x80\\x94 and hereâ\\x80\\x99s why  ',\n",
              "       'safe ways to heal your #acne!!    #altwaystoheal #healthy   #healing!! ',\n",
              "       ...,\n",
              "       '#hillary #campaigned today in #ohio((omg)) &amp; used words like \"assets&amp;liability\" never once did #clinton say thee(word) #radicalization   ',\n",
              "       'happy, at work conference: right mindset leads to culture-of-development organizations    #work #mindset',\n",
              "       'my   song \"so glad\" free download!  #shoegaze #newmusic #newsong'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cMFkmYjBQ3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16f75087-75e7-4c4e-ae4a-af5a7c066528"
      },
      "source": [
        "test_tweets[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'#studiolife #aislife #requires #passion #dedication #willpower   to find #newmaterialsâ\\x80¦ '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKsBDh1bBQ6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92c625ba-d8c1-42dd-eaa2-bd20b3067f74"
      },
      "source": [
        "predictor.predict(test_tweets[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opVCyeWpBQxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38c73138-35b8-4883-a62c-2fcd5e5bab04"
      },
      "source": [
        "test_tweets[1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "' @user #white #supremacists want everyone to see the new â\\x80\\x98  #birdsâ\\x80\\x99 #movie â\\x80\\x94 and hereâ\\x80\\x99s why  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PndM5dSG38W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b54b9c30-e81c-4c78-9cb1-242fe002f3aa"
      },
      "source": [
        "predictor.predict(test_tweets[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOVRRen8HDEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "db6dbb38-cba7-44db-ca7b-b383e0d43c44"
      },
      "source": [
        "test_tweets[179]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'seeing war craft in imax 3d ð\\x9f\\x98\\x84 #warcraftmovie   #imax #woohoo '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCfojY6gHDH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b0e13c0-982d-4a36-802f-cb8ea6b9864b"
      },
      "source": [
        "predictor.predict(test_tweets[179])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hd6EuIDHDDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "130f2d41-3500-42c6-dab3-52fb86de01cb"
      },
      "source": [
        "test_pred = predictor.predict(test_tweets)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J978cbN6IAFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e43e11ce-ae59-439a-e253-04b539adf857"
      },
      "source": [
        "test_pred"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '1',\n",
              " '0',\n",
              " '1',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '1',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfrKRdI3IAP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['label'] = test_pred\n",
        "\n",
        "submission = test[['id','label']]\n",
        "\n",
        "submission.to_csv('test_predictions.csv', index=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRVF7CGLJf3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.read_csv('test_predictions.csv')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXbesz7zPSbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "4c3689bd-4f6c-4b1e-e618-77d3a9b7246d"
      },
      "source": [
        "res"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17192</th>\n",
              "      <td>49155</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17193</th>\n",
              "      <td>49156</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17194</th>\n",
              "      <td>49157</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17195</th>\n",
              "      <td>49158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17196</th>\n",
              "      <td>49159</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17197 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  label\n",
              "0      31963      0\n",
              "1      31964      1\n",
              "2      31965      0\n",
              "3      31966      0\n",
              "4      31967      0\n",
              "...      ...    ...\n",
              "17192  49155      1\n",
              "17193  49156      0\n",
              "17194  49157      1\n",
              "17195  49158      0\n",
              "17196  49159      0\n",
              "\n",
              "[17197 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imGpWEt_Fmnj",
        "colab_type": "text"
      },
      "source": [
        "The `predictor.save` and `ktrain.load_predictor` methods can be used to save the Predictor object to disk and reload it at a later time to make predictions on new data."
      ]
    }
  ]
}